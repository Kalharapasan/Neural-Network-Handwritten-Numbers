{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2684a6a4-43ed-49a4-babe-b893074484e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python310\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\python310\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python310\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\python310\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python310\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\python310\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python310\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python310\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python310\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python310\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\python310\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python310\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97781e9f-1e0a-44a5-abf5-10d864705077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97119d3a-d58b-4573-b8e5-54a917819541",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitRecognizer, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a9592e4-f849-489a-bf91-9d3edae9bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_data = datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform\n",
    "    )\n",
    "    test_data = datasets.MNIST(\n",
    "        root='./data', train=False, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55337881-6a8b-44c3-ae54-96038dbdab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs=5, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    print(f\"Training on {device}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        accuracy = 100. * correct / total\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e525a24d-ecfd-4379-95a6-a431b0ea3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e9bc1a0-4a2c-4956-9529-cd2b3906aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_digit(model, image):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        if image.dim() == 3:\n",
    "            image = image.unsqueeze(0)\n",
    "        output = model(image)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        predicted = output.argmax(dim=1).item()\n",
    "        confidence = probabilities[0][predicted].item() * 100\n",
    "    \n",
    "    return predicted, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d21d2081-1305-42a2-972c-be9dad51b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, test_loader, num_samples=10):\n",
    "    model.eval()\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        img = images[i]\n",
    "        true_label = labels[i].item()\n",
    "        pred, conf = predict_digit(model, img)\n",
    "        \n",
    "        axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "        color = 'green' if pred == true_label else 'red'\n",
    "        axes[i].set_title(f\"Pred: {pred} ({conf:.1f}%)\\nTrue: {true_label}\", color=color)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('predictions.png', dpi=150)\n",
    "    plt.show()\n",
    "    print(\"Predictions saved to 'predictions.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2fe70e-2814-4d47-bd22-c29d991a5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path='digit_recognizer.pth'):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to '{path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65f0d969-4454-41b0-8687-b011bc060c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path='digit_recognizer.pth'):\n",
    "\n",
    "    model = DigitRecognizer()\n",
    "    model.load_state_dict(torch.load(path, weights_only=True))\n",
    "    print(f\"Model loaded from '{path}'\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102f16d-3d8a-40aa-8b38-c2109cd8eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Handwritten Digit Recognition\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    print(\"\\n[1/4] Loading MNIST dataset...\")\n",
    "    train_loader, test_loader = load_data(batch_size=64)\n",
    "    print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "    print(f\"Test samples: {len(test_loader.dataset)}\")\n",
    "\n",
    "    print(\"\\n[2/4] Creating neural network...\")\n",
    "    model = DigitRecognizer()\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Model parameters: {total_params:,}\")\n",
    "\n",
    "    print(\"\\n[3/4] Training model...\")\n",
    "    model = train(model, train_loader, epochs=5, lr=0.001)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
